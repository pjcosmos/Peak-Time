# database/py/1_ingest_top10.py
import os
import pandas as pd
import psycopg2
from dotenv import load_dotenv
from datetime import datetime

# âœ… .env ë¡œë“œ (í”„ë¡œì íŠ¸ ë£¨íŠ¸ì— .env ìˆì–´ì•¼ í•¨)
load_dotenv()

# âœ… ì¹´í…Œê³ ë¦¬ (DBì—ëŠ” ì´ ì½”ë“œë¡œ ì €ì¥ë¨)
CATEGORIES = {
    "sports": "ìŠ¤í¬ì¸ ",
    "climate": "ê¸°í›„",
    "entertainment": "ì—°ì˜ˆ/ë¬¸í™”",
    "finance_business": "ê¸ˆìœµ/ë¹„ì¦ˆë‹ˆìŠ¤",
}

# âœ… ì‹¤ì œ CSV íŒŒì¼ëª…ì— ì“°ì´ëŠ” ì½”ë“œ ë§¤í•‘
# - finance_business ì¹´í…Œê³ ë¦¬ëŠ” CSVëŠ” financeë¥¼ ì‚¬ìš©
FILE_CODE_MAP = {
    "sports": "sports",
    "climate": "climate",
    "entertainment": "entertainment",
    "finance_business": "finance",
}

# âœ… ì´ë¯¸ 1,2,3ì€ ë„£ì—ˆìœ¼ë‹ˆ 4ë²ˆë§Œ(= finance_businessë§Œ) ì‹¤í–‰
ONLY_INGEST_CODES = {"finance_business"}


def read_csv_safe(path: str) -> pd.DataFrame:
    try:
        return pd.read_csv(path, encoding="utf-8")
    except Exception:
        return pd.read_csv(path, encoding="cp949")


def get_db_url() -> str:
    """
    âœ… Railway(Postgres) ì—°ê²° URLì„ ì•ˆì „í•˜ê²Œ ê°€ì ¸ì˜¨ë‹¤.
    - 1ìˆœìœ„: í™˜ê²½ë³€ìˆ˜ DATABASE_URL (.env í¬í•¨)
    - ì—†ìœ¼ë©´ ì¦‰ì‹œ ì—ëŸ¬ë¡œ ì¤‘ë‹¨ (localhostë¡œ ë¶™ëŠ” ì‚¬ê³  ë°©ì§€)
    """
    url = os.getenv("DATABASE_URL")
    if not url:
        raise RuntimeError(
            "DATABASE_URLì´ ë¹„ì–´ìˆìŠµë‹ˆë‹¤.\n"
            "1) í”„ë¡œì íŠ¸ ë£¨íŠ¸ì— .env íŒŒì¼ ì¡´ì¬ í™•ì¸\n"
            "2) .envì— DATABASE_URL=postgresql://... í˜•íƒœë¡œ ì…ë ¥í–ˆëŠ”ì§€ í™•ì¸\n"
            "3) ì‹¤í–‰ í™˜ê²½(venv/uv/anaconda)ì—ì„œ .envê°€ ë¡œë“œë˜ëŠ”ì§€ í™•ì¸"
        )

    # Railwayì—ì„œ ê°€ë” postgres:// ë¡œ ì£¼ëŠ” ê²½ìš° í˜¸í™˜ ì²˜ë¦¬
    if url.startswith("postgres://"):
        url = url.replace("postgres://", "postgresql://", 1)

    return url


def ingest_top10():
    url = get_db_url()
    # ë¯¼ê°ì •ë³´ ë³´í˜¸: ì•ë¶€ë¶„ë§Œ ì¶œë ¥
    print("âœ… Using DATABASE_URL:", url.split("@")[0] + "@...")

    conn = psycopg2.connect(url)
    conn.autocommit = False
    cursor = conn.cursor()

    stats = {}

    for code, name in CATEGORIES.items():
        # âœ… 4ë²ˆë§Œ ë„£ê¸°
        if code not in ONLY_INGEST_CODES:
            print(f"â­ï¸ Skip (already ingested): {code}")
            continue

        file_code = FILE_CODE_MAP.get(code, code)
        print(f"ğŸ“‚ Category(DB): {code}  |  CSV(file_code): {file_code}")

        # 0) category í™•ë³´
        cursor.execute("SELECT category_id FROM category WHERE code = %s", (code,))
        cat_res = cursor.fetchone()

        if cat_res:
            cat_id = cat_res[0]
        else:
            cursor.execute(
                "INSERT INTO category (code, name_ko) VALUES (%s, %s) RETURNING category_id",
                (code, name),
            )
            cat_id = cursor.fetchone()[0]

        # 1) Collection Run
        base_date = "2026-02-25"
        cursor.execute(
            """
            INSERT INTO collection_run (country_code, category_id, period_start, period_end, is_dummy)
            VALUES ('KR', %s, %s, %s, FALSE)
            ON CONFLICT (country_code, category_id, period_start, period_end, is_dummy)
            DO UPDATE SET created_at = CURRENT_TIMESTAMP
            RETURNING run_id
            """,
            (cat_id, base_date, base_date),
        )
        run_id = cursor.fetchone()[0]

        # 2) Load & Merge Data (âœ… file_code ê¸°ì¤€)
        main_f = f"Top10_Trends/result/final_weighted_top10_{file_code}.csv"
        print("ğŸ“ main_f:", main_f)

        if not os.path.exists(main_f):
            print(f"âš ï¸ íŒŒì¼ ì—†ìŒ: {main_f}")
            continue

        df = read_csv_safe(main_f)

        # Supplemental data
        f_a = f"Top10_Trends/result/analyzed_top10_{file_code}.csv"
        if os.path.exists(f_a):
            df = df.merge(
                read_csv_safe(f_a)[
                    ["rank_title", "trend_type", "google_ratio(%)", "naver_ratio(%)"]
                ],
                on="rank_title",
                how="left",
            )

        f_q = f"Top10_Trends/result/quadrant/positioning_map_{file_code}.csv"
        if os.path.exists(f_q):
            df = df.merge(
                read_csv_safe(f_q)[
                    ["rank_title", "positioning", "volume_score", "momentum_score"]
                ],
                on="rank_title",
                how="left",
            )

        df = df.sort_values("total_score", ascending=False).head(10)

        for rank_idx, (_, row) in enumerate(df.iterrows(), start=1):
            # keyword upsert
            cursor.execute(
                """
                INSERT INTO keyword (keyword_text)
                VALUES (%s)
                ON CONFLICT (keyword_text)
                DO UPDATE SET created_at = CURRENT_TIMESTAMP
                RETURNING keyword_id
                """,
                (row["rank_title"],),
            )
            k_id = cursor.fetchone()[0]

            # keyword_score upsert
            cursor.execute(
                """
                INSERT INTO keyword_score (
                    run_id, keyword_id, rank_no, peak_time_index,
                    google_volume_text, naver_trend_sum,
                    platform_label, quadrant_label,
                    volume_score, momentum_score,
                    google_share_pct, naver_share_pct
                )
                VALUES (%s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s)
                ON CONFLICT (run_id, keyword_id)
                DO UPDATE SET
                    rank_no = EXCLUDED.rank_no,
                    peak_time_index = EXCLUDED.peak_time_index,
                    google_volume_text = EXCLUDED.google_volume_text,
                    naver_trend_sum = EXCLUDED.naver_trend_sum,
                    platform_label = EXCLUDED.platform_label,
                    quadrant_label = EXCLUDED.quadrant_label,
                    volume_score = EXCLUDED.volume_score,
                    momentum_score = EXCLUDED.momentum_score,
                    google_share_pct = EXCLUDED.google_share_pct,
                    naver_share_pct = EXCLUDED.naver_share_pct
                """,
                (
                    run_id,
                    k_id,
                    rank_idx,
                    row.get("total_score"),
                    str(row.get("google_absolute_volume")),
                    row.get("naver_trend_sum"),
                    row.get("trend_type"),
                    row.get("positioning"),
                    row.get("volume_score"),
                    row.get("momentum_score"),
                    row.get("google_ratio(%)"),
                    row.get("naver_ratio(%)"),
                ),
            )

        stats[code] = {"run_id": run_id, "count": len(df)}
        print(f"âœ… {code}: {len(df)} keywords inserted/updated. run_id={run_id}")

    conn.commit()
    cursor.close()
    conn.close()
    return stats


if __name__ == "__main__":
    ingest_top10()