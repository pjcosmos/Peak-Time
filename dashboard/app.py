import os
import streamlit as st
import pandas as pd
import plotly.express as px
from sqlalchemy import create_engine, text
from dotenv import load_dotenv

# .env íŒŒì¼ í™˜ê²½ë³€ìˆ˜ ë¡œë“œ
load_dotenv()

# 5. í˜ì´ì§€ ì„¤ì •
st.set_page_config(layout="wide", page_title="Peak-Time Trend Dashboard")

# -----------------------
# DB ì—°ê²° (Railway Postgres)
# -----------------------
def get_db_url():
    # 1. í™˜ê²½ë³€ìˆ˜(.env)ì—ì„œ ë¨¼ì € ì£¼ì†Œ ê°€ì ¸ì˜¤ê¸°
    db_url = os.environ.get("DATABASE_URL")
    if db_url:
        return db_url
        
    # 2. .envì— ì—†ë‹¤ë©´ Streamlit secrets í™•ì¸ (ì—ëŸ¬ ë°©ì§€ ì²˜ë¦¬)
    try:
        if "DATABASE_URL" in st.secrets:
            return st.secrets["DATABASE_URL"]
    except FileNotFoundError:
        pass
        
    return None

@st.cache_resource
def get_engine():
    db_url = get_db_url()
    if not db_url:
        st.error("DATABASE_URLì´ ì„¤ì •ë˜ì–´ ìˆì§€ ì•ŠìŠµë‹ˆë‹¤. (.env íŒŒì¼ ë˜ëŠ” í™˜ê²½ë³€ìˆ˜ë¥¼ í™•ì¸í•´ì£¼ì„¸ìš”)")
        st.stop()

    # Railwayê°€ postgres:// ë¡œ ì¤„ ë•Œ ë³´ì •
    if db_url.startswith("postgres://"):
        db_url = db_url.replace("postgres://", "postgresql+psycopg2://", 1)
    if db_url.startswith("postgresql://"):
        # SQLAlchemy ë“œë¼ì´ë²„ ëª…ì‹œ
        db_url = db_url.replace("postgresql://", "postgresql+psycopg2://", 1)

    return create_engine(db_url, pool_pre_ping=True)

engine = get_engine()

# -----------------------
# ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”
# -----------------------
if "selected_keyword_id" not in st.session_state:
    st.session_state.selected_keyword_id = None
if "selected_keyword_text" not in st.session_state:
    st.session_state.selected_keyword_text = None

# -----------------------
# DB ì¡°íšŒ í•¨ìˆ˜ë“¤
# -----------------------
@st.cache_data(ttl=60)
def load_categories():
    q = """
    SELECT category_id, code, name_ko
    FROM category
    ORDER BY name_ko ASC;
    """
    return pd.read_sql(text(q), engine)

@st.cache_data(ttl=60)
def load_latest_run_id(category_id: int, country_code: str = "KR", is_dummy: bool = False):
    q = """
    SELECT run_id
    FROM collection_run
    WHERE country_code = :country_code
      AND category_id = :category_id
      AND is_dummy = :is_dummy
    ORDER BY created_at DESC
    LIMIT 1;
    """
    df = pd.read_sql(
        text(q),
        engine,
        params={"country_code": country_code, "category_id": category_id, "is_dummy": is_dummy},
    )
    return int(df.iloc[0]["run_id"]) if not df.empty else None

@st.cache_data(ttl=60)
def load_top10(run_id: int):
    q = """
    SELECT
        ks.rank_no,
        k.keyword_id,
        k.keyword_text,
        ks.peak_time_index
    FROM keyword_score ks
    JOIN keyword k ON k.keyword_id = ks.keyword_id
    WHERE ks.run_id = :run_id
    ORDER BY ks.rank_no ASC
    LIMIT 10;
    """
    return pd.read_sql(text(q), engine, params={"run_id": run_id})

@st.cache_data(ttl=60)
def load_trend_series_7d(run_id: int, keyword_id: int):
    # ìµœê·¼ 7ì¼(google/naver í•©ì³ì„œ ìµœëŒ€ 14í–‰) ê°€ì ¸ì˜¨ í›„ ë‚ ì§œ ì˜¤ë¦„ì°¨ìˆœ ì •ë ¬
    q = """
    SELECT
        ts.d AS "ë‚ ì§œ",
        ts.value AS "ê²€ìƒ‰ëŸ‰",
        CASE
            WHEN lower(ts.source) = 'google' THEN 'Google'
            WHEN lower(ts.source) = 'naver'  THEN 'Naver'
            ELSE ts.source
        END AS "í”Œë«í¼"
    FROM trend_series ts
    WHERE ts.run_id = :run_id
      AND ts.keyword_id = :keyword_id
    ORDER BY ts.d DESC
    LIMIT 14;
    """
    df = pd.read_sql(text(q), engine, params={"run_id": run_id, "keyword_id": keyword_id})
    if df.empty:
        return df
    df = df.sort_values(["ë‚ ì§œ", "í”Œë«í¼"], ascending=[True, True]).reset_index(drop=True)
    return df

@st.cache_data(ttl=60)
def load_news_top3_latest(run_id: int, keyword_id: int):
    q = """
    SELECT title, url, publisher, published_at
    FROM news_article
    WHERE run_id = :run_id
      AND keyword_id = :keyword_id
    ORDER BY published_at DESC NULLS LAST, collected_at DESC
    LIMIT 3;
    """
    return pd.read_sql(text(q), engine, params={"run_id": run_id, "keyword_id": keyword_id})

@st.cache_data(ttl=60)
def load_youtube_top3_by_views(run_id: int, keyword_id: int):
    q = """
    SELECT title, channel_title, youtube_id, view_count, published_at
    FROM youtube_video
    WHERE run_id = :run_id
      AND keyword_id = :keyword_id
    ORDER BY view_count DESC NULLS LAST, published_at DESC
    LIMIT 3;
    """
    return pd.read_sql(text(q), engine, params={"run_id": run_id, "keyword_id": keyword_id})

def infer_trend_badge(top10_df: pd.DataFrame, keyword_id: int):
    """
    ë„¤ ìŠ¤í‚¤ë§ˆì— up/down/newê°€ ì—†ì–´ì„œ ì„ì‹œ ê·œì¹™:
    peak_time_index ìƒìœ„3=up, í•˜ìœ„3=down, ë‚˜ë¨¸ì§€=new
    """
    s = top10_df.sort_values("peak_time_index", ascending=False).reset_index(drop=True)
    pos = int(s.index[s["keyword_id"] == keyword_id][0]) + 1
    if pos <= 3:
        return "up"
    if pos >= 8:
        return "down"
    return "new"

# -----------------------
# 4. ì‚¬ì´ë“œë°”: ì¹´í…Œê³ ë¦¬ ì„ íƒ (DB ê¸°ë°˜)
# -----------------------
st.sidebar.title("Peak-Time")

cats = load_categories()
if cats.empty:
    st.warning("category í…Œì´ë¸”ì´ ë¹„ì–´ìˆìŠµë‹ˆë‹¤. ì‹œë“œ ë°ì´í„°ë¶€í„° ë„£ì–´ì£¼ì„¸ìš”.")
    st.stop()

selected_cat_name = st.sidebar.selectbox("ì¹´í…Œê³ ë¦¬ ì„ íƒ", cats["name_ko"].tolist())
selected_cat = cats[cats["name_ko"] == selected_cat_name].iloc[0]
category_id = int(selected_cat["category_id"])

# ìµœì‹  run ì°¾ê¸°
run_id = load_latest_run_id(category_id=category_id, country_code="KR", is_dummy=False)
if not run_id:
    st.warning("í•´ë‹¹ ì¹´í…Œê³ ë¦¬ì— collection_run(ìµœì‹ , KR, is_dummy=false)ì´ ì—†ìŠµë‹ˆë‹¤.")
    st.stop()

# 3. í™”ë©´ ë¶„í•  (1:2 ë¹„ìœ¨)
left_col, right_col = st.columns([1, 2])

# 2. ì¢Œì¸¡ íŒ¨ë„ (TOP 10 ë¦¬ìŠ¤íŠ¸)
with left_col:
    st.subheader(f"ğŸ”¥ {selected_cat_name} TOP 10")

    top10 = load_top10(run_id)
    if top10.empty:
        st.warning("keyword_score ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
        st.stop()

    for _, row in top10.iterrows():
        i = int(row["rank_no"])
        kw_id = int(row["keyword_id"])
        kw_text = row["keyword_text"]

        rank_col, btn_col, trend_col = st.columns([0.15, 0.65, 0.2])

        # 1) ìˆœìœ„ ìˆ«ì ê¾¸ë¯¸ê¸°
        rank_color = "#4285F4" if i <= 3 else "#A0C3FF"
        with rank_col:
            st.markdown(
                f'<div style="color: {rank_color}; font-size: 18px; font-weight: bold; text-align: center; padding-top: 8px;">{i}</div>',
                unsafe_allow_html=True
            )

        # 2) í‚¤ì›Œë“œ ë²„íŠ¼
        with btn_col:
            if st.button(kw_text, key=f"kw_{kw_id}", use_container_width=True):
                st.session_state.selected_keyword_id = kw_id
                st.session_state.selected_keyword_text = kw_text
                st.rerun()

        # 3) íŠ¸ë Œë“œ ì•„ì´ì½˜ ê¾¸ë¯¸ê¸° (ì„ì‹œ ë°°ì§€)
        with trend_col:
            trend = infer_trend_badge(top10, kw_id)
            if trend == "up":
                trend_html = '<div style="color: #D93025; font-size: 18px; font-weight: bold; text-align: center; padding-top: 8px;">â†‘</div>'
            elif trend == "down":
                trend_html = '<div style="color: #1A73E8; font-size: 18px; font-weight: bold; text-align: center; padding-top: 8px;">â†“</div>'
            else:
                trend_html = '<div style="color: #D93025; font-size: 12px; font-weight: bold; text-align: center; padding-top: 12px;">NEW</div>'
            st.markdown(trend_html, unsafe_allow_html=True)

# 1. ìš°ì¸¡ íŒ¨ë„ (ì‹¬ì¸µ ë¶„ì„ ë·°)
with right_col:
    if st.session_state.selected_keyword_id:
        kw_id = st.session_state.selected_keyword_id
        kw_text = st.session_state.selected_keyword_text

        st.subheader(f"ğŸ” '{kw_text}' ì‹¬ì¸µ ë¶„ì„")

        # ìƒë‹¨: êµ¬ê¸€ vs ë„¤ì´ë²„ 7ì¼ ê²€ìƒ‰ëŸ‰ ë¹„êµ ë¼ì¸ ì°¨íŠ¸
        df = load_trend_series_7d(run_id, kw_id)
        if df.empty:
            st.info("trend_series ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
        else:
            fig = px.line(
                df,
                x="ë‚ ì§œ",
                y="ê²€ìƒ‰ëŸ‰",
                color="í”Œë«í¼",
                title="ìµœê·¼ 7ì¼ ê²€ìƒ‰ íŠ¸ë Œë“œ ë¹„êµ",
                markers=True,
                template="plotly_white"
            )
            st.plotly_chart(fig, use_container_width=True)

        # í•˜ë‹¨: ê´€ë ¨ ë‰´ìŠ¤ ë° ìœ íŠœë¸Œ ë°˜ì‘ (TOP3)
        news_col, youtube_col = st.columns(2)

        with news_col:
            st.info("ğŸ“° ê´€ë ¨ ë‰´ìŠ¤ (ìµœì‹  TOP3)")
            news_df = load_news_top3_latest(run_id, kw_id)
            if news_df.empty:
                st.write("ê´€ë ¨ ë‰´ìŠ¤ê°€ ì—†ìŠµë‹ˆë‹¤.")
            else:
                for idx, n in news_df.iterrows():
                    pub = n["publisher"] if pd.notna(n["publisher"]) else ""
                    dt = n["published_at"]
                    dt_txt = dt.strftime("%Y-%m-%d %H:%M") if pd.notna(dt) else ""
                    st.write(f"**{idx+1}. [{pub}] {n['title']}**")
                    if dt_txt:
                        st.caption(f"ë°œí–‰: {dt_txt}")
                    st.write(n["url"])

        with youtube_col:
            st.error("ğŸ¥ ìœ íŠœë¸Œ ë°˜ì‘ (ì¡°íšŒìˆ˜ TOP3 ë¹„êµ)")
            yt_df = load_youtube_top3_by_views(run_id, kw_id)
            if yt_df.empty:
                st.write("ê´€ë ¨ ìœ íŠœë¸Œ ì˜ìƒì´ ì—†ìŠµë‹ˆë‹¤.")
            else:
                yt_df["view_count"] = yt_df["view_count"].fillna(0).astype(int)
                top1_views = int(yt_df["view_count"].max()) or 1

                for idx, y in yt_df.iterrows():
                    views = int(y["view_count"])
                    ratio = views / top1_views

                    st.write(f"**{idx+1}. {y['title']}**")
                    st.caption(f"{y['channel_title']} Â· ì¡°íšŒìˆ˜ {views:,} Â· TOP1 ëŒ€ë¹„ {ratio:.0%}")
                    st.progress(min(max(ratio, 0.0), 1.0))

                    if pd.notna(y["youtube_id"]):
                        st.write(f"https://www.youtube.com/watch?v={y['youtube_id']}")
    else:
        st.write("ğŸ‘ˆ ë¶„ì„í•  í‚¤ì›Œë“œë¥¼ ì¢Œì¸¡ ë¦¬ìŠ¤íŠ¸ì—ì„œ ì„ íƒí•´ì£¼ì„¸ìš”.")