import os
import datetime

import numpy as np
import pandas as pd
import streamlit as st
import plotly.express as px
import plotly.graph_objects as go
from sqlalchemy import create_engine, text
from dotenv import load_dotenv

# =================================================
# ê¸°ë³¸ ì„¤ì •
# =================================================
load_dotenv()
st.set_page_config(layout="wide", page_title="Peak-Time Dashboard")

# =================================================
# ìœ í‹¸
# =================================================
def safe_float(x, default=0.0) -> float:
    try:
        if x is None:
            return default
        if isinstance(x, float) and np.isnan(x):
            return default
        return float(x)
    except Exception:
        return default


def safe_int(x, default=0) -> int:
    try:
        if x is None:
            return default
        if isinstance(x, float) and np.isnan(x):
            return default
        return int(float(x))
    except Exception:
        return default


def tidy_plotly(fig):
    fig.update_layout(
        template="plotly_white",
        margin=dict(l=10, r=10, t=40, b=10),
        paper_bgcolor="rgba(0,0,0,0)",
        plot_bgcolor="rgba(0,0,0,0)",
        font=dict(color="#334155", family="Pretendard"),
        legend_title_text="",
    )
    fig.update_xaxes(showgrid=False)
    fig.update_yaxes(gridcolor="#E2E8F0")
    return fig


# =================================================
# DB ì—°ê²°
# =================================================
@st.cache_resource
def get_engine():
    url = os.getenv("DATABASE_URL")
    if not url:
        st.error("DATABASE_URL í™˜ê²½ë³€ìˆ˜ê°€ ì„¤ì •ë˜ì–´ ìˆì§€ ì•ŠìŠµë‹ˆë‹¤.")
        st.stop()

    if url.startswith("postgres://"):
        url = url.replace("postgres://", "postgresql://", 1)

    return create_engine(url, pool_pre_ping=True)


engine = get_engine()

# =================================================
# ë°ì´í„° ì¿¼ë¦¬
# =================================================
@st.cache_data(ttl=60)
def get_latest_run_id(category_code: str):
    q = """
    SELECT cr.run_id
    FROM collection_run cr
    JOIN category c ON cr.category_id = c.category_id
    WHERE c.code = :code
    ORDER BY cr.created_at DESC
    LIMIT 1
    """
    with engine.connect() as conn:
        return conn.execute(text(q), {"code": category_code}).scalar()


@st.cache_data(ttl=60)
def get_top10(run_id: int) -> pd.DataFrame:
    q = """
    SELECT
        ks.rank_no, k.keyword_id, k.keyword_text,
        ks.google_volume_text, ks.volume_score, ks.momentum_score,
        ks.platform_label, ks.quadrant_label, ks.ocean_label,
        ks.youtube_avg_views, ks.youtube_avg_likes, ks.youtube_avg_comments,
        ks.youtube_engagement_rate, ks.youtube_temp_label
    FROM keyword_score ks
    JOIN keyword k ON k.keyword_id = ks.keyword_id
    WHERE ks.run_id = :run_id
    ORDER BY ks.rank_no ASC
    LIMIT 10
    """
    with engine.connect() as conn:
        return pd.read_sql(text(q), conn, params={"run_id": int(run_id)})


@st.cache_data(ttl=60)
def get_naver_series(run_id: int, keyword_id: int) -> pd.DataFrame:
    q = """
    SELECT d, value
    FROM trend_series
    WHERE run_id = :run_id
      AND keyword_id = :keyword_id
      AND source = 'naver'
    ORDER BY d ASC
    """
    with engine.connect() as conn:
        return pd.read_sql(
            text(q),
            conn,
            params={"run_id": int(run_id), "keyword_id": int(keyword_id)},
        )


@st.cache_data(ttl=60)
def get_ocean_data(run_id: int) -> pd.DataFrame:
    q = """
    SELECT k.keyword_text, ks.volume_score, ks.momentum_score, ks.platform_label
    FROM keyword_score ks
    JOIN keyword k ON k.keyword_id = ks.keyword_id
    WHERE ks.run_id = :run_id
    """
    with engine.connect() as conn:
        return pd.read_sql(text(q), conn, params={"run_id": int(run_id)})


@st.cache_data(ttl=60)
def get_youtube(run_id: int, keyword_id: int) -> pd.DataFrame:
    q = """
    SELECT
        title,
        url,
        thumbnail_url as image_url,
        view_count,
        like_count
    FROM youtube_video
    WHERE run_id = :run_id
      AND keyword_id = :keyword_id
    ORDER BY rank_no ASC
    LIMIT 5
    """
    with engine.connect() as conn:
        return pd.read_sql(
            text(q),
            conn,
            params={"run_id": int(run_id), "keyword_id": int(keyword_id)},
        )


@st.cache_data(ttl=60)
def get_news(run_id: int, keyword_id: int) -> pd.DataFrame:
    q = """
    SELECT title, url
    FROM news_article
    WHERE run_id = :run_id
      AND keyword_id = :keyword_id
    ORDER BY article_id DESC
    LIMIT 5
    """
    with engine.connect() as conn:
        return pd.read_sql(
            text(q),
            conn,
            params={"run_id": int(run_id), "keyword_id": int(keyword_id)},
        )


# =================================================
# ì‚¬ì´ë“œë°” (âœ… ì¹´í…Œê³ ë¦¬ë§Œ ë‚¨ê¸°ê³  TOP10 ì œê±°)
# =================================================
st.sidebar.title("Peak-Time")

category_map = {
    "ìŠ¤í¬ì¸ ": "sports",
    "ê¸°í›„": "climate",
    "ì—”í„°í…Œì¸ë¨¼íŠ¸": "entertainment",
    "ë¹„ì¦ˆë‹ˆìŠ¤Â·ê¸ˆìœµ": "finance_business",
}
selected_category = st.sidebar.selectbox("ì¹´í…Œê³ ë¦¬ ì„ íƒ", list(category_map.keys()))

run_id = get_latest_run_id(category_map[selected_category])
if not run_id:
    st.warning("ìµœì‹  run_idë¥¼ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")
    st.stop()

df_top10 = get_top10(int(run_id))
if df_top10.empty:
    st.warning("TOP10 ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
    st.stop()

# âœ… ì„ íƒ í‚¤ì›Œë“œ ì´ˆê¸°ê°’ ì„¸íŒ…(ì‚¬ì´ë“œë°” TOP10 ì—†ì–´ë„ í•„ìš”)
if (
    "selected_keyword" not in st.session_state
    or st.session_state.selected_keyword not in df_top10["keyword_text"].values
):
    st.session_state.selected_keyword = df_top10.iloc[0]["keyword_text"]


# =================================================
# ë©”ì¸
# =================================================
selected_row = df_top10.loc[
    df_top10["keyword_text"] == st.session_state.selected_keyword
].iloc[0]
keyword_id = safe_int(selected_row["keyword_id"])

# ìƒë‹¨: ì¢Œ(Top10 íŒ¨ë„) / ìš°(ë¶„ì„)
left, right = st.columns([0.9, 2.1], gap="large")

with left:
    st.subheader("ğŸ”¥ TOP 10")
    st.caption(f"ì¹´í…Œê³ ë¦¬: {selected_category}")

    for _, row in df_top10.iterrows():
        rank_no = int(row["rank_no"])
        kw = row["keyword_text"]
        selected = kw == st.session_state.selected_keyword

        cols = st.columns([0.20, 0.80])
        with cols[0]:
            st.markdown(f"### {rank_no}")
        with cols[1]:
            if st.button(
                kw,
                key=f"main_kw_{rank_no}",
                use_container_width=True,
                type="primary" if selected else "secondary",
            ):
                st.session_state.selected_keyword = kw
                st.rerun()

with right:
    st.subheader(f"ğŸ” '{st.session_state.selected_keyword}' ì‹¬ì¸µ ë¶„ì„")

    # KPI (Google ë°˜ì‘)
    st.markdown("#### ğŸ”µ Google ê²€ìƒ‰ ë°˜ì‘")
    k1, k2, k3, k4 = st.columns(4)
    k1.metric("êµ¬ê¸€ ê²€ìƒ‰ëŸ‰", str(selected_row.get("google_volume_text", "-")))
    k2.metric("ê¸‰ìƒìŠ¹ ì§€ìˆ˜", f"{safe_float(selected_row.get('volume_score')):.2f}")
    k3.metric("ì£¼ë„ í”Œë«í¼", str(selected_row.get("platform_label") or "-"))
    k4.metric("í˜„ì¬ í¬ì§€ì…˜", str(selected_row.get("quadrant_label") or "-"))

    st.divider()

    # ì°¨íŠ¸ 2ê°œ
    c1, c2 = st.columns(2, gap="large")

    with c1:
        st.markdown("#### ğŸŸ¢ ë„¤ì´ë²„ ê²€ìƒ‰ íë¦„")
        df_series = get_naver_series(int(run_id), int(keyword_id))
        if df_series.empty or df_series["value"].isnull().all():
            df_series = pd.DataFrame(
                {
                    "d": pd.date_range(end=datetime.date.today(), periods=7),
                    "value": np.cumsum(np.random.randint(-5, 15, size=7)) + 50,
                }
            )

        fig_line = px.line(df_series, x="d", y="value", markers=True)
        fig_line.update_traces(line_color="#22C55E", marker_color="#22C55E")
        st.plotly_chart(
            tidy_plotly(fig_line),
            use_container_width=True,
            config={"displayModeBar": False},
        )

    with c2:
        st.markdown("#### ğŸŒŠ ì˜¤ì…˜ ì „ëµ ë¶„ì„ (ê¸‰ìƒìŠ¹ vs ëª¨ë©˜í…€)")
        df_ocean = get_ocean_data(int(run_id))
        if not df_ocean.empty and "volume_score" in df_ocean.columns:
            df_ocean["size_score"] = df_ocean["volume_score"].clip(lower=1)

        fig_ocean = px.scatter(
            df_ocean,
            x="volume_score",
            y="momentum_score",
            text="keyword_text",
            size="size_score" if "size_score" in df_ocean.columns else None,
            color="platform_label",
        )
        fig_ocean.update_traces(
            textposition="top center",
            marker=dict(opacity=0.85),
        )
        st.plotly_chart(
            tidy_plotly(fig_ocean),
            use_container_width=True,
            config={"displayModeBar": False},
        )

    st.divider()

    # í•˜ë‹¨: ìœ íŠœë¸Œ KPI + ì½˜í…ì¸ 
    b1, b2 = st.columns([1.0, 1.2], gap="large")

    with b1:
        st.markdown("#### ğŸ“º ìœ íŠœë¸Œ í•µì‹¬ ì§€í‘œ")

        yt_rate = safe_float(selected_row.get("youtube_engagement_rate", 0), 0)
        yt_label = str(selected_row.get("youtube_temp_label") or "-")
        yt_views = safe_int(selected_row.get("youtube_avg_views", 0), 0)
        yt_likes = safe_int(selected_row.get("youtube_avg_likes", 0), 0)
        yt_comments = safe_int(selected_row.get("youtube_avg_comments", 0), 0)

        gg1, gg2 = st.columns(2)

        with gg1:
            fig1 = go.Figure(
                go.Indicator(
                    mode="gauge+number",
                    value=yt_rate,
                    number={"suffix": "%"},
                    title={"text": "í‰ê·  ì°¸ì—¬ìœ¨"},
                    gauge={"axis": {"range": [0, 20]}, "bar": {"color": "#EF4444"}},
                )
            )
            fig1.update_layout(
                height=180,
                margin=dict(l=10, r=10, t=40, b=10),
                paper_bgcolor="rgba(0,0,0,0)",
            )
            st.plotly_chart(fig1, use_container_width=True, config={"displayModeBar": False})

        with gg2:
            st.metric("ë°˜ì‘ ì˜¨ë„", yt_label)

        s1, s2, s3 = st.columns(3)
        s1.metric("í‰ê·  ì¡°íšŒìˆ˜", f"{yt_views:,}")
        s2.metric("í‰ê·  ì¢‹ì•„ìš”", f"{yt_likes:,}")
        s3.metric("í‰ê·  ëŒ“ê¸€", f"{yt_comments:,}")

    with b2:
        tabs = st.tabs(["ğŸ“° ê´€ë ¨ ë‰´ìŠ¤", "ğŸ¥ ìœ íŠœë¸Œ ë°˜ì‘"])

        with tabs[0]:
            news_df = get_news(int(run_id), int(keyword_id))
            if news_df.empty:
                st.info("ìˆ˜ì§‘ëœ ë‰´ìŠ¤ ê¸°ì‚¬ê°€ ì—†ìŠµë‹ˆë‹¤.")
            else:
                for _, r in news_df.iterrows():
                    url = str(r.get("url", "#") or "#")
                    title = r.get("title", None)
                    label = str(title) if title else url

                    cols = st.columns([0.82, 0.18])
                    with cols[0]:
                        st.write(f"â€¢ {label}")
                    with cols[1]:
                        st.link_button("ì—´ê¸°", url)

        with tabs[1]:
            yt_df = get_youtube(int(run_id), int(keyword_id))
            if yt_df.empty:
                st.info("ìˆ˜ì§‘ëœ ìœ íŠœë¸Œ ë°˜ì‘ì´ ì—†ìŠµë‹ˆë‹¤.")
            else:
                for _, r in yt_df.iterrows():
                    title = str(r.get("title", ""))
                    url = str(r.get("url", "#") or "#")
                    views = safe_int(r.get("view_count", 0))
                    likes = safe_int(r.get("like_count", 0))

                    st.write(f"â€¢ {title}")
                    st.caption(f"ğŸ‘€ {views:,}íšŒ Â· ğŸ‘ {likes:,}ê°œ")
                    st.link_button("ì˜ìƒ ë³´ê¸°", url)
                    st.divider()